<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name='keywords' content="">

    
    <meta property="og:title" content="Learning Note on GPU - yao hsiao">
    <meta name="apple-mobile-web-app-title" content="Learning Note on GPU - yao hsiao">

    
    <meta name="description" content="Learning Note on GPU">
    <meta property="og:description" content="Learning Note on GPU">

    
    <meta name="author" content="Yao Hsiao">
    
    


    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Learning Note on GPU"/>
<meta name="twitter:description" content="Learning Note on GPU"/>


    <base href="https://yaohsiaopid.github.io/posts/gpu_notes/">
    <title>
  Learning Note on GPU · yao hsiao
</title>

    <link rel="canonical" href="https://yaohsiaopid.github.io/posts/gpu_notes/">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700|Merriweather:300,700|Source+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css" integrity="sha256-oSrCnRYXvHG31SBifqP2PM1uje7SJUyX0nTwO2RJV54=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="https://yaohsiaopid.github.io/css/coder.min.2a473c402be4328818abe1753d7346bd4f2ee551b16be30947a31dc574d52dab.css" integrity="sha256-Kkc8QCvkMogYq&#43;F1PXNGvU8u5VGxa&#43;MJR6MdxXTVLas=" crossorigin="anonymous" media="screen" />
    

    

    

    
      <link rel="stylesheet" href="https://yaohsiaopid.github.io/css/custom.css">
    

    <link rel="icon" type="image/png" href="https://yaohsiaopid.github.io/img/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://yaohsiaopid.github.io/img/favicon-16x16.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.53" />
  </head>

  <body class=" ">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://yaohsiaopid.github.io">
      yao hsiao
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://yaohsiaopid.github.io/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://yaohsiaopid.github.io/about/">About</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Learning Note on GPU</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2019-12-01T22:34:55&#43;08:00'>
                December 1, 2019
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              4 minutes read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://yaohsiaopid.github.io/categories/gpu/">gpu</a></div>

          
        </div>
      </header>

      <div>
        

<h1 id="gpu">GPU</h1>

<h2 id="cuda-intro">Cuda intro</h2>

<h3 id="gpu-introduction">GPU introduction</h3>

<p><img src="https://i.imgur.com/RJaOX7Q.png" alt="" /></p>

<ul>
<li>memory: global &ndash;&gt; PBSM (per block shared memory) &ndash;&gt; local register</li>

<li><p>multiple stream multi-processors (SM):</p>

<ul>
<li>vector machine, share register file, programmable cache</li>
</ul>

<p><img src="https://i.imgur.com/1vfxsXy.png" alt="http://www.ece.lsu.edu/gp/refs/gf100-whitepaper.pdf" /></p></li>
</ul>

<h3 id="cuda">Cuda</h3>

<ul>
<li><p>Kernel = Many Concurrent Threads
<img src="https://i.imgur.com/zx1Cx8y.png" alt="" /></p>

<ul>
<li>kernel = grid of thread blocks</li>
<li>Each thread executes the same code but <strong>on the different data based on its threadID</strong></li>
<li>threads are grouped into thread blocks
<img src="https://i.imgur.com/pBZ2VJO.png" alt="" /></li>
<li>blocks are independent to each other
<img src="https://i.imgur.com/TgO0qAl.png" alt="" /></li>
</ul></li>

<li><p>Thread Level Scheduling - Warp</p></li>

<li><p><img src="https://i.imgur.com/5LjZZGJ.jpg" alt="" /></p>

<ul>
<li><p>Once a thread block is scheduled to an SM, threads in the thread block are further partitioned into warps.</p>

<ul>
<li>warp consists of 32 consecutive threads and all threads in a warp are executed in SIMT ie all threads exe the same instructions but on its own private data</li>
<li>Threads in a warp will be executing the same instruction</li>

<li><p>Instructions are issued per warp
&gt; Keep the number of threads per block a multiple of warp size (32).
&gt; Avoid small block sizes: Start with at least 128 or 256 threads per block.
&gt; Adjust block size up or down according to kernel resource requirements.</p>

<h3 id="cuda-language">cuda language</h3></li>
</ul></li>
</ul></li>

<li><p><code>kernelFunc&lt;&lt;&lt; nB, nT, nS, Sid &gt;&gt;&gt;(...);</code></p>

<ul>
<li><code>nB</code>: number of block per grid</li>
<li><code>nT</code>: number of threads per block</li>
<li><code>nS</code>: shared memory size</li>
</ul></li>

<li><p><code>threadIdx; blockIdx; blockDim; gridDim</code></p>

<ul>
<li>eg1
<code>cuda
dim3 grid(3,2):
dim3 blk(5,3);
my_kernel&lt;&lt;&lt; grid, blk&gt;&gt;&gt;();
// (x,y) or (x,y,z)
</code></li>
<li>eg2
<code>cuda
// Kernel definition
__global__ void VecAdd(float* A)
{
int i = threadIdx.x * blockDim.x + threadIdx.y;
A[i] = A[i] + 1;
} 
//...
size=10; dim3 blk(size, size); 
my_kernel&lt;&lt;&lt; 1, blk &gt;&gt;&gt;(A, size);
</code></li>
<li>blockDim.x: number of threads per block</li>
<li>
<br /></li>
</ul></li>

<li><p>function qualifier:</p>

<ul>
<li><code>__device__</code>: Executed on the device, Callable from the device only</li>
<li><code>__global__</code>: Executed on the device, <strong>Callable from the host only (must have void return type!)</strong></li>
</ul></li>

<li><p>Variable qualifier:</p>

<ul>
<li><code>__device__</code>: device’s global memory (shared among SMs) space</li>
<li><code>__constant__</code></li>
<li><code>__shared__</code>:  in <strong>thread block&rsquo;s</strong> shared memory</li>
</ul></li>

<li><p>Program compilation</p>

<ul>
<li><img src="https://i.imgur.com/KFZk7wH.png" alt="" /></li>
</ul></li>

<li><p>Kernel Time Measurement</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cuda" data-lang="cuda">cudaEvent_t start, stop;
cudaEventCreate(&amp;start);
cudaEventCreate(&amp;stop);
cudaEventRecord(start);
kernel&lt;&lt;&lt;block, thread&gt;&gt;&gt;();
cudaEventRecord(stop);
cudaEventSynchronize(stop);
float time;
cudaEventElapsedTime(&amp;time, start, stop);</code></pre></div></li>

<li><p>Dynamic Parallelism</p>

<ul>
<li>launch new grids from the GPU</li>
<li><a href="http://on-demand.gputechconf.com/gtc/2012/presentations/S0338-New-Features-in-the-CUDA-Programming-Model.pdf">http://on-demand.gputechconf.com/gtc/2012/presentations/S0338-New-Features-in-the-CUDA-Programming-Model.pdf</a></li>
</ul></li>
</ul>

<h2 id="gpu-architecture">GPU Architecture</h2>

<h3 id="thread-execution">Thread execution</h3>

<ul>
<li>execution model</li>
</ul>

<p><img src="https://i.imgur.com/WmxrPpk.png" alt="" /></p>

<p><img src="https://i.imgur.com/k0ijWsk.png" alt="" /></p>

<p><img src="https://i.imgur.com/lJLOxS2.png" alt="" /></p>

<p><img src="https://i.imgur.com/9W7DzDt.png" alt="" /></p>

<ul>
<li>Hardware schedules thread blocks onto available SMs</li>

<li><p>warp</p>

<ul>
<li>At any time, only one warp is executed per SM</li>
<li>All threads in a Warp execute the same instruction when selected</li>
<li>Threads in a wrap execute physically in parallel</li>
<li>Warps and blocks execute logically in paralle
<br /></li>
</ul>

<p><img src="https://i.imgur.com/RdK7TaU.png" alt="" /></p></li>
</ul>

<h3 id="memory-hierarchy">memory hierarchy</h3>

<p><img src="https://i.imgur.com/OxKdgHC.png" alt="" /></p>

<ul>
<li>registers

<ul>
<li>consumes zero extra clock cycles per instruction, except

<ul>
<li>Register memory bank conflicts</li>
</ul></li>
<li>not indexable

<ul>
<li><strong>Array variables</strong> always are allocated in <strong>local memory</strong></li>
</ul></li>
<li>Register spilling: Local memory is used if the register limit is met

<ul>
<li>limit: cuda6.1:

<ul>
<li>65K registers per block</li>
<li>255 registers per thread</li>
</ul></li>
</ul></li>
</ul></li>

<li><p>local memory</p>

<ul>
<li>Usually when one runs out of SM resources</li>
<li>&ldquo;local&rdquo; for each thread has its own private area</li>
<li><strong>Array variables</strong> always are allocated in <strong>local memory</strong></li>
<li>Stores are cached in L1</li>

<li><p>Not really a “memory” – bytes are stored in global memory (DRAM)
<img src="https://i.imgur.com/uMnl1h2.png" alt="" /></p></li>

<li><p>eg.</p></li>
</ul>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">__device__ void distance(int m, int n, int *V){
int i, j, k; // register
int a[10], b[10], c[10]; // local memory, off-chip DRAM
...
} </pre></div></li>

<li><p>shared memory</p>

<ul>
<li>shared by all the <strong>threads in a block</strong></li>
<li>Size: at most 48K per block (CUDA 6.1)</li>
<li><code>extern __shared__ &lt;type&gt; &lt;name&gt;[]</code> (pg.7)</li>

<li><p>dyanmic allocation: <code>nS</code> in <code>func&lt;&lt;&lt;nB, nT, nS&gt;&gt;&gt;(..);</code></p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cuda" data-lang="cuda">extern __shared__ int S[][];
__global__ void FW_APSP(int k, int D[n][n]) {
int i = threadIdx.x;
int j = threadIdx.y;
S[i][j]=D[i][j]; // move data to shared memory
__syncthreads();
// do computation
if (S[i][j]&gt;S[i][k]+S[k][j])
D[i][j]= S[i][k]+S[k][j];
}</code></pre></div></li>

<li><p>architecture</p>

<ul>
<li>Each bank can service one address per cycle</li>
<li>Shared memory is as fast as register if no bank conflict</li>
<li>Shared memory banks are organized such that successive 32-bit words are assigned to successive banks and the bandwidth is 32 bits per bank per clock cycle.</li>
<li>For devices of compute capability 1.x, the warp size is 32 threads and the number of banks is 16</li>
<li><a href="https://stackoverflow.com/questions/7903566/how-is-2d-shared-memory-arranged-in-cuda">https://stackoverflow.com/questions/7903566/how-is-2d-shared-memory-arranged-in-cuda</a>
<br /></li>
</ul>

<p><img src="https://i.imgur.com/j0CG2L0.png" alt="" /></p></li>
</ul></li>

<li><p>global memory</p>

<ul>
<li>memory coalescing

<ul>
<li>Global memory access happens in transactions of 32 or 128 bytes</li>
<li>The hardware will try to reduce to as few transactions as possible</li>
<li>Coalesced access:
&gt; A group of 32 contiguous threads (&ldquo;warp&rdquo;) accessing adjacent words. Few transactions and high utilization
<br /></li>
</ul></li>
</ul></li>

<li><p>constant memory</p>

<ul>
<li>Same usage and scope as the global memory except

<ul>
<li>Read only</li>
<li>Declare by variable qualifier <code>__constant__</code></li>
<li>Move by cudaMemcpyToSymbol() &amp; cudaMemcpyFromSymbol()</li>
</ul></li>
</ul></li>

<li><p>warp divergence
<img src="https://i.imgur.com/t2dsPrn.png" alt="" /></p></li>
</ul>

<h2 id="share-memory">share memory</h2>

<ul>
<li>ref: <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory-5-x">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory-5-x</a></li>
<li>For compute capability 5.x and 6.x:

<ul>
<li>Shared memory has 32 banks that are organized such that successive <strong>32-bit words</strong> map to successive banks. Each bank has a bandwidth of 32 bits per clock cycle.</li>
<li>bank index = (byte address / 4 bytes per bank) % 32 banks</li>
</ul></li>
</ul>

<p><strong>to be continue (update please refer to <a href="https://hackmd.io/@yaohsiaopid/ryHNKkxTr">link</a>)</strong></p>

<h2 id="reference">Reference</h2>

<ul>
<li><a href="https://docs.nvidia.com/cuda/">https://docs.nvidia.com/cuda/</a></li>
<li><a href="https://nanxiao.me/en/about/">https://nanxiao.me/en/about/</a></li>
<li><a href="http://www.icl.utk.edu/~luszczek/teaching/courses/fall2016/cosc462/pdf/GPU_Fundamentals.pdf">http://www.icl.utk.edu/~luszczek/teaching/courses/fall2016/cosc462/pdf/GPU_Fundamentals.pdf</a></li>
<li><a href="https://medium.com/@smallfishbigsea/basic-concepts-in-gpu-computing-3388710e9239">https://medium.com/@smallfishbigsea/basic-concepts-in-gpu-computing-3388710e9239</a></li>
<li><a href="https://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf">https://www.nvidia.com/content/PDF/fermi_white_papers/NVIDIA_Fermi_Compute_Architecture_Whitepaper.pdf</a></li>
<li><a href="http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_WarpsAndOccupancy.pdf">http://on-demand.gputechconf.com/gtc-express/2011/presentations/cuda_webinars_WarpsAndOccupancy.pdf</a></li>
<li><a href="https://devblogs.nvidia.com/cuda-pro-tip-nvprof-your-handy-universal-gpu-profiler/">https://devblogs.nvidia.com/cuda-pro-tip-nvprof-your-handy-universal-gpu-profiler/</a></li>
<li><a href="http://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf">http://www.enseignement.polytechnique.fr/profs/informatique/Eric.Goubault/Cours09/CUDA/SC07_CUDA_5_Optimization_Harris.pdf</a></li>
<li><a href="http://on-demand.gputechconf.com/gtc-express/2011/presentations/StreamsAndConcurrencyWebinar.pdf">http://on-demand.gputechconf.com/gtc-express/2011/presentations/StreamsAndConcurrencyWebinar.pdf</a></li>
<li><a href="http://on-demand.gputechconf.com/gtc-express/2011/presentations/NVIDIA_GPU_Computing_Webinars_CUDA_Memory_Optimization.pdf">http://on-demand.gputechconf.com/gtc-express/2011/presentations/NVIDIA_GPU_Computing_Webinars_CUDA_Memory_Optimization.pdf</a></li>
<li><a href="http://on-demand.gputechconf.com/gtc-express/2011/presentations/GTC_Express_Sarah_Tariq_June2011.pdf">http://on-demand.gputechconf.com/gtc-express/2011/presentations/GTC_Express_Sarah_Tariq_June2011.pdf</a></li>
<li></li>
</ul>

      </div>

      <footer>
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yourdiscussshortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
      <p>yaohsiaopid at gmail.com</p>
    
     © 2019
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

  </body>

</html>
